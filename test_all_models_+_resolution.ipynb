{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test all models + resolution",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShirelShemesh/organizational_structure/blob/master/test_all_models_%2B_resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-Vc8VSOP2dg"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3d9PH93P4Lc"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.2.Pretrained_NER_Profiling_Pipelines.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cna9gw7PE20s"
      },
      "source": [
        "# i = []\n",
        "# while(True):\n",
        "#     i.append('a')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvfxxPCJ32RQ",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2d147d82-e54c-4c1f-aaae-1fae02b0b593"
      },
      "source": [
        "import json, os\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f6a9434-5fdb-48ff-9192-7743f9c9b0f7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1f6a9434-5fdb-48ff-9192-7743f9c9b0f7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spark_nlp_for_healthcare_spark_ocr_3344.json to spark_nlp_for_healthcare_spark_ocr_3344.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6i2awB24SDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c38744-c47f-41e5-ba82-aad7e8f5ba22"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 212.4 MB 68 kB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 71.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 136 kB 25.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIAhFKMo4U3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d956a9-1f23-4a3d-df4e-a59344c834eb"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "\"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "\"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 3.3.2\n",
            "Spark NLP_JSL Version : 3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geGwx2WU-7GY"
      },
      "source": [
        "# Clinical NER Model Profiling Pretrained Pipeline\n",
        "\n",
        "This pipeline can be used to explore all the available pretrained NER models at once. When you run this pipeline over your text, you will end up with the predictions coming out of each pretrained clinical NER model trained with `embeddings_clinical`.\n",
        "\n",
        "|Clinical NER Model List|\n",
        "|-|\n",
        "|ner_ade_clinical|\n",
        "|ner_posology_greedy|\n",
        "|ner_risk_factors|\n",
        "|jsl_ner_wip_clinical|\n",
        "|ner_human_phenotype_gene_clinical|\n",
        "|jsl_ner_wip_greedy_clinical|\n",
        "|ner_cellular|\n",
        "|ner_cancer_genetics|\n",
        "|jsl_ner_wip_modifier_clinical|\n",
        "|ner_drugs_greedy|\n",
        "|ner_deid_sd_large|\n",
        "|ner_diseases|\n",
        "|nerdl_tumour_demo|\n",
        "|ner_deid_subentity_augmented|\n",
        "|ner_jsl_enriched|\n",
        "|ner_genetic_variants|\n",
        "|ner_bionlp|\n",
        "|ner_measurements_clinical|\n",
        "|ner_diseases_large|\n",
        "|ner_radiology|\n",
        "|ner_deid_augmented|\n",
        "|ner_anatomy|\n",
        "|ner_chemprot_clinical|\n",
        "|ner_posology_experimental|\n",
        "|ner_drugs|\n",
        "|ner_deid_sd|\n",
        "|ner_posology_large|\n",
        "|ner_deid_large|\n",
        "|ner_posology|\n",
        "|ner_deidentify_dl|\n",
        "|ner_deid_enriched|\n",
        "|ner_bacterial_species|\n",
        "|ner_drugs_large|\n",
        "|ner_clinical_large|\n",
        "|jsl_rd_ner_wip_greedy_clinical|\n",
        "|ner_medmentions_coarse|\n",
        "|ner_radiology_wip_clinical|\n",
        "|ner_clinical|\n",
        "|ner_chemicals|\n",
        "|ner_deid_synthetic|\n",
        "|ner_events_clinical|\n",
        "|ner_posology_small|\n",
        "|ner_anatomy_coarse|\n",
        "|ner_human_phenotype_go_clinical|\n",
        "|ner_jsl_slim|\n",
        "|ner_jsl|\n",
        "|ner_jsl_greedy|\n",
        "|ner_events_admission_clinical|\n",
        "\n",
        "You can check [Models Hub](https://nlp.johnsnowlabs.com/models) page for more information about all these models and more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M59c1OjPmW1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a6036e-0915-4a79-c1e2-ccb1575a5a75"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "clinical_profiling_pipeline = PretrainedPipeline(\"ner_profiling_clinical\", \"en\", \"clinical/models\")\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ner_profiling_clinical download started this may take some time.\n",
            "Approx size to download 2.3 GB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GYCnYmMnU-H"
      },
      "source": [
        "text = \"\"\"67 year old with metastatic breast cancer, COPD (on chronic prednisone and home O2), \n",
        "            paroxysmal afib who presents with worsening SOB and some confusion. \n",
        "            She has had malignant left pleural effusion that was last drained on February 10.\n",
        "            She is taking tamoxifen for her breast cancer. She was last admitted on 02/02/2018 and discharged with home hospice/palliative care. \n",
        "            In terms of her cardiac issues, she was reportedly diagnosed with afib in 2011. \n",
        "            She had an echo at that time showing normal LV function. Most recently, she had an echo November 2012 showing EF 35-40%. \n",
        "            It does not appear that she underwent any ischemia evaluation.\"\"\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoiJTdxC_Mej"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_colwidth', 0)\n",
        "\n",
        "\n",
        "def get_codes (lp, text, vocab, hcc=False):\n",
        "    \n",
        "    full_light_result = lp.fullAnnotate(text)\n",
        "\n",
        "    codes = []\n",
        "    distances =[]\n",
        "    resolutions=[]\n",
        "\n",
        "    for chunk, code in zip(full_light_result[0]['ner_chunk'], full_light_result[0][vocab]):\n",
        "        codes.append(code.result) \n",
        "        distances.append(code.metadata['all_k_distances'].split(':::')[0])\n",
        "        resolutions.append(code.metadata['all_k_resolutions'].split(':::')[0])\n",
        "\n",
        "    distance = 'distance:', distances\n",
        "    \n",
        "    return vocab, codes, distance, resolutions"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GJFg2AKpxam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a53722c-ab23-43ae-db5b-7e57f3f6ed3b"
      },
      "source": [
        "clinical_result = clinical_profiling_pipeline.annotate(text)\n",
        "clinical_result.keys()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ner_ade_clinical_chunks', 'ner_deid_augmented', 'ner_posology_greedy_chunks', 'ner_radiology_wip_clinical', 'ner_deidentify_dl', 'ner_jsl_slim', 'ner_risk_factors_chunks', 'jsl_ner_wip_clinical_chunks', 'ner_deid_synthetic', 'ner_drugs_greedy', 'ner_human_phenotype_gene_clinical_chunks', 'ner_events_admission_clinical', 'jsl_ner_wip_greedy_clinical_chunks', 'ner_posology_greedy', 'ner_cellular_chunks', 'ner_cancer_genetics_chunks', 'ner_jsl_greedy', 'jsl_ner_wip_modifier_clinical_chunks', 'ner_drugs_greedy_chunks', 'ner_deid_sd_large_chunks', 'ner_diseases_chunks', 'ner_diseases_large', 'ner_chemprot_clinical', 'ner_posology_large', 'nerdl_tumour_demo_chunks', 'ner_deid_subentity_augmented_chunks', 'ner_jsl_enriched_chunks', 'ner_genetic_variants_chunks', 'ner_chexpert', 'ner_bionlp_chunks', 'ner_measurements_clinical_chunks', 'ner_diseases_large_chunks', 'ner_drugs_large', 'ner_clinical_large', 'ner_chemicals', 'ner_radiology_chunks', 'ner_bacterial_species', 'ner_deid_augmented_chunks', 'ner_bionlp', 'ner_anatomy_chunks', 'ner_deid_large', 'jsl_ner_wip_modifier_clinical', 'ner_chemprot_clinical_chunks', 'nerdl_tumour_demo', 'ner_posology_experimental_chunks', 'ner_cancer_genetics', 'ner_posology_small', 'ner_drugs_chunks', 'ner_deid_sd_chunks', 'ner_human_phenotype_gene_clinical', 'ner_ade_clinical', 'ner_human_phenotype_go_clinical', 'ner_risk_factors', 'ner_clinical', 'ner_posology_large_chunks', 'ner_cellular', 'ner_deid_large_chunks', 'ner_posology_chunks', 'ner_deidentify_dl_chunks', 'ner_deid_enriched_chunks', 'ner_deid_sd_large', 'jsl_ner_wip_greedy_clinical', 'ner_bacterial_species_chunks', 'ner_diseases', 'jsl_rd_ner_wip_greedy_clinical', 'ner_drugs', 'ner_drugs_large_chunks', 'ner_clinical_large_chunks', 'ner_anatomy_coarse', 'token', 'ner_medmentions_coarse', 'ner_deid_sd', 'jsl_rd_ner_wip_greedy_clinical_chunks', 'ner_medmentions_coarse_chunks', 'ner_anatomy', 'ner_deid_enriched', 'ner_deid_subentity_augmented', 'ner_radiology_wip_clinical_chunks', 'ner_clinical_chunks', 'ner_measurements_clinical', 'ner_chexpert_chunks', 'ner_chemicals_chunks', 'ner_jsl_enriched', 'ner_deid_synthetic_chunks', 'ner_events_clinical_chunks', 'ner_posology_experimental', 'jsl_ner_wip_clinical', 'ner_posology_small_chunks', 'ner_anatomy_coarse_chunks', 'ner_human_phenotype_go_clinical_chunks', 'ner_jsl', 'ner_events_clinical', 'ner_jsl_slim_chunks', 'ner_jsl_chunks', 'ner_jsl_greedy_chunks', 'ner_genetic_variants', 'ner_radiology', 'ner_posology', 'sentence', 'ner_events_admission_clinical_chunks'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJZ8U5eSr7fo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72c9f168-1013-4e7c-db09-4d44fe5fca7a"
      },
      "source": [
        "print(\"Clinical Text: \\n\", text, \"\\n \\nResults:\\n\")\n",
        "\n",
        "# for i in clinical_result.keys():\n",
        "#   print(\"{} : \".format(i), clinical_result[i])\n",
        "\n",
        "print(\"{} : \".format(\"ner_drugs_greedy_chunks\"), clinical_result[\"ner_drugs_greedy_chunks\"])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clinical Text: \n",
            " 67 year old with metastatic breast cancer, COPD (on chronic prednisone and home O2), \n",
            "            paroxysmal afib who presents with worsening SOB and some confusion. \n",
            "            She has had malignant left pleural effusion that was last drained on February 10.\n",
            "            She is taking tamoxifen for her breast cancer. She was last admitted on 02/02/2018 and discharged with home hospice/palliative care. \n",
            "            In terms of her cardiac issues, she was reportedly diagnosed with afib in 2011. \n",
            "            She had an echo at that time showing normal LV function. Most recently, she had an echo November 2012 showing EF 35-40%. \n",
            "            It does not appear that she underwent any ischemia evaluation. \n",
            " \n",
            "Results:\n",
            "\n",
            "ner_drugs_greedy_chunks :  ['prednisone', 'tamoxifen']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwSDAgsyEG_f"
      },
      "source": [
        "def isBlank (myString):\n",
        "    return not (myString and myString.strip() and not myString == \".\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMh2NiU2Gb6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa4b2e3-0c57-4218-e493-01f680fe04da"
      },
      "source": [
        "# initialize assembler & embedder for entity resolving \n",
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "sbert_embedder = BertSentenceEmbeddings\\\n",
        "      .pretrained('sbiobert_base_cased_mli', 'en','clinical/models')\\\n",
        "      .setInputCols([\"ner_chunk\"])\\\n",
        "      .setOutputCol(\"sbert_embeddings\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbiobert_base_cased_mli download started this may take some time.\n",
            "Approximate size to download 384.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRI0oOOBFc0p"
      },
      "source": [
        "def get_rxNorm_code(text):\n",
        "      \n",
        "  print('getting code for ', text)\n",
        "  rxnorm_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_rxnorm\",\"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"ner_chunk\", \"sbert_embeddings\"]) \\\n",
        "      .setOutputCol(\"rxnorm_code\")\\\n",
        "      .setDistanceFunction(\"EUCLIDEAN\")\n",
        "\n",
        "  rxnorm_pipelineModel = PipelineModel(\n",
        "    stages = [\n",
        "        documentAssembler,\n",
        "        sbert_embedder,\n",
        "        rxnorm_resolver])\n",
        "  \n",
        "  rxnorm_lp = LightPipeline(rxnorm_pipelineModel)\n",
        "\n",
        "  code = get_codes (rxnorm_lp, text, vocab='rxnorm_code')\n",
        "  print('code for ', text, 'is: ', code)\n",
        "  return(code)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQt8Ie7ZtpVc"
      },
      "source": [
        "def get_snomed_code(text):\n",
        "      \n",
        "  print('getting code for ', text)\n",
        "  snomed_ct_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_snomed_findings_aux_concepts\",\"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"ner_chunk\", \"sbert_embeddings\"]) \\\n",
        "      .setOutputCol(\"snomed_code\")\\\n",
        "      .setDistanceFunction(\"EUCLIDEAN\")\n",
        "\n",
        "  snomed_pipelineModel = PipelineModel(\n",
        "      stages = [\n",
        "          documentAssembler,\n",
        "          sbert_embedder,\n",
        "          snomed_ct_resolver])\n",
        "\n",
        "  snomed_lp = LightPipeline(snomed_pipelineModel)\n",
        "\n",
        "\n",
        "  code = get_codes (snomed_lp, text, vocab='snomed_code', aux_label=True)\n",
        "  print('code for ', text, 'is: ', code)\n",
        "  return(code)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKclYggVGP-m"
      },
      "source": [
        "def get_icd10_code(text):\n",
        "      \n",
        "  icd10_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_icd10cm_augmented\",\"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"ner_chunk\", \"sbert_embeddings\"]) \\\n",
        "        .setOutputCol(\"icd10cm_code\")\\\n",
        "        .setDistanceFunction(\"EUCLIDEAN\")\n",
        "\n",
        "  icd_pipelineModel = PipelineModel(\n",
        "      stages = [\n",
        "          documentAssembler,\n",
        "          sbert_embedder,\n",
        "          icd10_resolver])\n",
        "\n",
        "  icd_lp = LightPipeline(icd_pipelineModel)\n",
        "\n",
        "  return get_codes (icd_lp, text, vocab='rxnorm_code')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9onAk-VFP5g"
      },
      "source": [
        "def get_rxnorm_resolution(text):\n",
        "  print('resolving rxNorm resolution for text:', text)\n",
        "  results = {'rxnorm code':get_rxNorm_code(text)}\n",
        "  print(results)\n",
        "  return results\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k32C-ccewDNn"
      },
      "source": [
        "def get_snomed_resolution(text):\n",
        "  print('resolving snomed resolution for text:', text)\n",
        "  results = {'snomed code':get_snomed_code(text)}\n",
        "  print(results)\n",
        "  return results\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uycShnP6wYr6"
      },
      "source": [
        "# def init_clinical_RE_model():\n",
        "#   documenter = DocumentAssembler()\\\n",
        "#     .setInputCol(\"text\")\\\n",
        "#     .setOutputCol(\"document\")\n",
        "\n",
        "#   sentencer = SentenceDetector()\\\n",
        "#       .setInputCols([\"document\"])\\\n",
        "#       .setOutputCol(\"sentences\")\n",
        "\n",
        "#   tokenizer = sparknlp.annotators.Tokenizer()\\\n",
        "#       .setInputCols([\"sentences\"])\\\n",
        "#       .setOutputCol(\"tokens\")\n",
        "\n",
        "#   words_embedder = WordEmbeddingsModel()\\\n",
        "#       .pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "#       .setInputCols([\"sentences\", \"tokens\"])\\\n",
        "#       .setOutputCol(\"embeddings\")\n",
        "\n",
        "#   pos_tagger = PerceptronModel()\\\n",
        "#       .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
        "#       .setInputCols([\"sentences\", \"tokens\"])\\\n",
        "#       .setOutputCol(\"pos_tags\")\n",
        "\n",
        "#   events_admission_ner_tagger = MedicalNerModel()\\\n",
        "#       .pretrained(\"ner_events_admission_clinical\", \"en\", \"clinical/models\")\\\n",
        "#       .setInputCols(\"sentences\", \"tokens\", \"embeddings\")\\\n",
        "#       .setOutputCol(\"ner_tags\")   \n",
        "\n",
        "#   ner_chunker = NerConverterInternal()\\\n",
        "#       .setInputCols([\"sentences\", \"tokens\", \"ner_tags\"])\\\n",
        "#       .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "#   dependency_parser = DependencyParserModel()\\\n",
        "#       .pretrained(\"dependency_conllu\", \"en\")\\\n",
        "#       .setInputCols([\"sentences\", \"pos_tags\", \"tokens\"])\\\n",
        "#       .setOutputCol(\"dependencies\")\n",
        "\n",
        "#   clinical_re_Model = RelationExtractionModel()\\\n",
        "#       .pretrained(\"re_temporal_events_clinical\", \"en\", 'clinical/models')\\\n",
        "#       .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunk\", \"dependencies\"])\\\n",
        "#       .setOutputCol(\"relations\")\\\n",
        "#       .setMaxSyntacticDistance(4)\\\n",
        "#       .setPredictionThreshold(0.9)\n",
        "\n",
        "#   pipeline = Pipeline(stages=[\n",
        "#       documenter,\n",
        "#       sentencer,\n",
        "#       tokenizer, \n",
        "#       words_embedder, \n",
        "#       pos_tagger, \n",
        "#       events_admission_ner_tagger,\n",
        "#       ner_chunker,\n",
        "#       dependency_parser,\n",
        "#       clinical_re_Model\n",
        "#   ])\n",
        "\n",
        "\n",
        "#   empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "#   return pipeline.fit(empty_data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipKESG3h1kQy"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# def get_clinical_assertion_light (light_model, text):\n",
        "\n",
        "#   light_result = light_model.fullAnnotate(text)[0]\n",
        "\n",
        "#   status=[]\n",
        "\n",
        "#   for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
        "      \n",
        "#       status.append(m.result)\n",
        "\n",
        "#   return status\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def get_clinical_assertion_light (light_result):\n",
        "\n",
        "  chunks=[]\n",
        "  entities=[]\n",
        "  status=[]\n",
        "\n",
        "  print('light result to assert is:',light_result)\n",
        "\n",
        "  # light_result = light_result\n",
        "  for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
        "      \n",
        "      chunks.append(n.result)\n",
        "      entities.append(n.metadata['entity']) \n",
        "      status.append(m.result)\n",
        "\n",
        "  df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status})\n",
        "\n",
        "  return df"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWuJUiJzgQqh"
      },
      "source": [
        "**Lets show chunk results of NER models in a pandas dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UByUbfv7KU8"
      },
      "source": [
        "def get_relations_df (results, col='relations'):\n",
        "  print('getting relations for:',results)\n",
        "  rel_pairs=[]\n",
        "  for rel in results[0][col]:\n",
        "    rel_pairs.append(dict(\n",
        "        result=rel.result, \n",
        "        entity1=rel.metadata['entity1'], \n",
        "        entity1_begin=rel.metadata['entity1_begin'],\n",
        "        entity1_end=rel.metadata['entity1_end'],\n",
        "        chunk1=rel.metadata['chunk1'], \n",
        "        entity2=rel.metadata['entity2'],\n",
        "        entity2_begin=rel.metadata['entity2_begin'],\n",
        "        entity2_end=rel.metadata['entity2_end'],\n",
        "        chunk2=rel.metadata['chunk2'], \n",
        "        confidence=rel.metadata['confidence']\n",
        "    ))\n",
        "\n",
        "  return rel_pairs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91-Uwcdoyc2T"
      },
      "source": [
        " from sparknlp_jsl.annotator import *\n",
        "def get_assertions(text, pipeline):\n",
        "\n",
        "  print('trying to assert...')\n",
        "  empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "  model = pipeline.fit(empty_data)\n",
        "  light_model = LightPipeline(model)\n",
        "\n",
        "\n",
        "  light_result = light_model.fullAnnotate(text)[0]\n",
        "\n",
        "  chunks=[]\n",
        "  entities=[]\n",
        "  status=[]\n",
        "\n",
        "  print('assertion:',light_result)\n",
        "\n",
        "  for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
        "      \n",
        "      chunks.append(n.result)\n",
        "      entities.append(n.metadata['entity']) \n",
        "      status.append(m.result)\n",
        "          \n",
        "  df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status})\n",
        "\n",
        "  return df"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4YqeODk-bK1"
      },
      "source": [
        "def get_ner_drugs_pipeline():\n",
        "  documentAssembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "  # Sentence Detector annotator, processes various sentences per line\n",
        "\n",
        "  sentenceDetector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "  # Tokenizer splits words in a relevant format for NLP\n",
        "\n",
        "  tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "  # Clinical word embeddings trained on PubMED dataset\n",
        "  word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "  # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
        "  clinical_ner = MedicalNerModel\\\n",
        "      .pretrained(\"ner_drugs_greedy\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setIncludeAllConfidenceScores(True)\n",
        "\n",
        "  ner_converter = NerConverter() \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "\n",
        "  pos_tagger = PerceptronModel()\\\n",
        "      .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"pos_tags\")\n",
        "\n",
        "  events_admission_ner_tagger = MedicalNerModel()\\\n",
        "      .pretrained(\"ner_drugs_greedy\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"sentence\", \"token\", \"embeddings\")\\\n",
        "      .setOutputCol(\"ner_tags\")   \n",
        "\n",
        "  ner_chunker = NerConverterInternal()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner_tags\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "  dependency_parser = DependencyParserModel()\\\n",
        "      .pretrained(\"dependency_conllu\", \"en\")\\\n",
        "      .setInputCols([\"sentence\", \"pos_tags\", \"token\"])\\\n",
        "      .setOutputCol(\"dependencies\")\n",
        "\n",
        "  clinical_re_Model = RelationExtractionModel()\\\n",
        "      .pretrained(\"re_temporal_events_clinical\", \"en\", 'clinical/models')\\\n",
        "      .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunk\", \"dependencies\"])\\\n",
        "      .setOutputCol(\"relations\")\\\n",
        "      .setMaxSyntacticDistance(4)\\\n",
        "      .setPredictionThreshold(0.9)\n",
        "\n",
        "\n",
        "  # Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
        "  # coming from sparknlp_jsl.annotator !!\n",
        "  clinical_assertion = AssertionDLModel.pretrained(\"assertion_dl_healthcare\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"assertion\")\n",
        "      \n",
        "  \n",
        "  pipeline = Pipeline(stages=[\n",
        "      documentAssembler,\n",
        "      sentenceDetector,\n",
        "      tokenizer, \n",
        "      word_embeddings, \n",
        "      clinical_ner,\n",
        "      ner_converter,\n",
        "      clinical_assertion,\n",
        "      pos_tagger, \n",
        "      events_admission_ner_tagger,\n",
        "      ner_chunker,\n",
        "      dependency_parser,\n",
        "      clinical_re_Model\n",
        "  ])\n",
        "\n",
        "  return pipeline\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyBchYg_kZ8N"
      },
      "source": [
        "def get_ner_diseases_pipeline():\n",
        "  documentAssembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "  # Sentence Detector annotator, processes various sentences per line\n",
        "\n",
        "  sentenceDetector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "  # Tokenizer splits words in a relevant format for NLP\n",
        "\n",
        "  tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "  # Clinical word embeddings trained on PubMED dataset\n",
        "  word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "  # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
        "  clinical_ner = MedicalNerModel\\\n",
        "      .pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setIncludeAllConfidenceScores(True)\n",
        "\n",
        "  ner_converter = NerConverter() \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "\n",
        "  pos_tagger = PerceptronModel()\\\n",
        "      .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"pos_tags\")\n",
        "\n",
        "  events_admission_ner_tagger = MedicalNerModel()\\\n",
        "      .pretrained(\"jsl_ner_wip_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"sentence\", \"token\", \"embeddings\")\\\n",
        "      .setOutputCol(\"ner_tags\")   \n",
        "\n",
        "  ner_chunker = NerConverterInternal()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner_tags\"])\\\n",
        "      .setOutputCol(\"ner_chunks\")\n",
        "\n",
        "  dependency_parser = DependencyParserModel()\\\n",
        "      .pretrained(\"dependency_conllu\", \"en\")\\\n",
        "      .setInputCols([\"sentence\", \"pos_tags\", \"token\"])\\\n",
        "      .setOutputCol(\"dependencies\")\n",
        "\n",
        "  clinical_re_Model = RelationExtractionModel()\\\n",
        "      .pretrained(\"re_temporal_events_clinical\", \"en\", 'clinical/models')\\\n",
        "      .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunks\", \"dependencies\"])\\\n",
        "      .setOutputCol(\"relations\")\\\n",
        "      .setMaxSyntacticDistance(4)\\\n",
        "      .setPredictionThreshold(0.9)\n",
        "\n",
        "\n",
        "  # Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
        "  # coming from sparknlp_jsl.annotator !!\n",
        "  clinical_assertion = AssertionDLModel.pretrained(\"assertion_dl\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"assertion\")\n",
        "      \n",
        "  \n",
        "  pipeline = Pipeline(stages=[\n",
        "      documentAssembler,\n",
        "      sentenceDetector,\n",
        "      tokenizer, \n",
        "      word_embeddings, \n",
        "      clinical_ner,\n",
        "      ner_converter,\n",
        "      clinical_assertion,\n",
        "      pos_tagger, \n",
        "      events_admission_ner_tagger,\n",
        "      ner_chunker,\n",
        "      dependency_parser,\n",
        "      clinical_re_Model\n",
        "  ])\n",
        "\n",
        "  return pipeline\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gep8uY3jo8Y"
      },
      "source": [
        "def get_ner_posology_pipeline():\n",
        "  documentAssembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "  # Sentence Detector annotator, processes various sentences per line\n",
        "\n",
        "  sentenceDetector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "  # Tokenizer splits words in a relevant format for NLP\n",
        "\n",
        "  tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "  # Clinical word embeddings trained on PubMED dataset\n",
        "  word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "  # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
        "  clinical_ner = MedicalNerModel\\\n",
        "      .pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setIncludeAllConfidenceScores(True)\n",
        "\n",
        "  ner_converter = NerConverter() \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "\n",
        "  pos_tagger = PerceptronModel()\\\n",
        "      .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"pos_tags\")\n",
        "\n",
        "  events_admission_ner_tagger = MedicalNerModel()\\\n",
        "      .pretrained(\"ner_posology\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"sentence\", \"token\", \"embeddings\")\\\n",
        "      .setOutputCol(\"ner_tags\")   \n",
        "\n",
        "  ner_chunker = NerConverterInternal()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner_tags\"])\\\n",
        "      .setOutputCol(\"ner_chunks\")\n",
        "\n",
        "  dependency_parser = DependencyParserModel()\\\n",
        "      .pretrained(\"dependency_conllu\", \"en\")\\\n",
        "      .setInputCols([\"sentence\", \"pos_tags\", \"token\"])\\\n",
        "      .setOutputCol(\"dependencies\")\n",
        "\n",
        "  clinical_re_Model = RelationExtractionModel()\\\n",
        "      .pretrained(\"re_temporal_events_clinical\", \"en\", 'clinical/models')\\\n",
        "      .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunks\", \"dependencies\"])\\\n",
        "      .setOutputCol(\"relations\")\\\n",
        "      .setMaxSyntacticDistance(4)\\\n",
        "      .setPredictionThreshold(0.9)\n",
        "\n",
        "\n",
        "  # Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
        "  # coming from sparknlp_jsl.annotator !!\n",
        "  clinical_assertion = AssertionDLModel.pretrained(\"assertion_jsl\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"assertion\")\n",
        "      \n",
        "  \n",
        "  pipeline = Pipeline(stages=[\n",
        "      documentAssembler,\n",
        "      sentenceDetector,\n",
        "      tokenizer, \n",
        "      word_embeddings, \n",
        "      clinical_ner,\n",
        "      ner_converter,\n",
        "      clinical_assertion,\n",
        "      pos_tagger, \n",
        "      events_admission_ner_tagger,\n",
        "      ner_chunker,\n",
        "      dependency_parser,\n",
        "      clinical_re_Model\n",
        "  ])\n",
        "\n",
        "  return pipeline\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF5-xW6W_zqe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_drugs_chunk_result(original_text, light_result, model_name, pipeline):\n",
        "\n",
        "  print('getting chunk results for light result:',light_result)\n",
        "  \n",
        "  all_relations = get_relations_extraction(original_text, pipeline)\n",
        "  print('all relations for this text are:',all_relations)\n",
        "  all_assertions = get_assertions(original_text, pipeline)\n",
        "  print('all assertions for this text are:',all_assertions)\n",
        "\n",
        "  sentences = []\n",
        "  begins = []\n",
        "  ends = []\n",
        "  chunks = []\n",
        "  entities = []\n",
        "  confidences = []\n",
        "  resolutions = []\n",
        "  assertions = []\n",
        "  relations = []\n",
        "  # original_text_relations = []\n",
        "\n",
        "\n",
        "  for n in (light_result):\n",
        "\n",
        "    sentences.append(n.metadata['sentence'])\n",
        "    begins.append(n.begin)\n",
        "    ends.append(n.end) \n",
        "    chunks.append(n.result)\n",
        "    entities.append(n.metadata['entity'])\n",
        "    confidences.append(n.metadata['confidence'])\n",
        "    resolutions.append(get_rxNorm_code(n.result))\n",
        "\n",
        "    matching_relations = []\n",
        "    \n",
        "\n",
        "    for r in all_relations:\n",
        "      if (('chunk1' in r and r['chunk1'] == n.result) or ('chunk2' in r and r['chunk2'] == n.result)):\n",
        "        matching_relations.append(r)\n",
        "    relations.append(matching_relations)\n",
        "\n",
        "\n",
        "    matching_assertions = all_assertions.loc[all_assertions.chunks == n.result,'assertion']\n",
        "\n",
        "    # assertions.append(all_assertions.loc[all_assertions['chunks'] == n.result]['assertion'])\n",
        "    # assertions.append(all_assertions.loc[all_assertions.loc[all_assertions['chunks'] == n.result],'assertion'].values[0])\n",
        "    # assertions.append(all_assertions.loc[all_assertions.chunks == n.result],'assertion'].values[0])\n",
        "    if (len(matching_assertions) > 0):\n",
        "      matching_assertions = matching_assertions.values[0]\n",
        "    assertions.append(matching_assertions)\n",
        "\n",
        "    # assertions.append(matching_assertions)\n",
        "      # relations.append(all_relations.loc[all_relations['chunk1'] == n.result] or all_relations.loc[df['chunk2'] == n.result])\n",
        "    \n",
        "    # relations.append(all_relations.loc[all_relations['chunk1'] == n.result] or all_relations.loc[df['chunk2'] == n.result])\n",
        "      \n",
        "    df = pd.DataFrame({'sentence':sentences, 'begin': begins, 'end': ends, 'chunks': chunks, 'entity': entities, 'confidence': confidences, 'resolution': resolutions, 'assertion': assertions, 'relations': relations})\n",
        "\n",
        "    print(\"\\n \\n\", \"*\"*20, model_name, \"Model Results\", \"*\"*20)\n",
        "    \n",
        "    display(df)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdaS-Q_1xWAw"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_diseases_chunk_result(original_text, light_result, model_name, pipeline):\n",
        "\n",
        "  print('getting chunk results for light result:',light_result)\n",
        "  \n",
        "  # all_relations = get_relations_extraction(original_text, pipeline)\n",
        "  # print('all relations for this text are:',all_relations)\n",
        "  all_assertions = get_assertions(original_text, pipeline)\n",
        "  print('all assertions for this text are:',all_assertions)\n",
        "\n",
        "  sentences = []\n",
        "  begins = []\n",
        "  ends = []\n",
        "  chunks = []\n",
        "  entities = []\n",
        "  confidences = []\n",
        "  resolutions = []\n",
        "  assertions = []\n",
        "  # relations = []\n",
        "  # original_text_relations = []\n",
        "\n",
        "\n",
        "  for n in (light_result):\n",
        "\n",
        "    sentences.append(n.metadata['sentence'])\n",
        "    begins.append(n.begin)\n",
        "    ends.append(n.end) \n",
        "    chunks.append(n.result)\n",
        "    entities.append(n.metadata['entity'])\n",
        "    confidences.append(n.metadata['confidence'])\n",
        "    resolutions.append(get_snomed_code(n.result))\n",
        "\n",
        "    matching_relations = []\n",
        "    \n",
        "\n",
        "    # for r in all_relations:\n",
        "    #   if (('chunk1' in r and r['chunk1'] == n.result) or ('chunk2' in r and r['chunk2'] == n.result)):\n",
        "    #     matching_relations.append(r)\n",
        "    # relations.append(matching_relations)\n",
        "\n",
        "\n",
        "    matching_assertions = all_assertions.loc[all_assertions.chunks == n.result,'assertion']\n",
        "\n",
        "    # assertions.append(all_assertions.loc[all_assertions['chunks'] == n.result]['assertion'])\n",
        "    # assertions.append(all_assertions.loc[all_assertions.loc[all_assertions['chunks'] == n.result],'assertion'].values[0])\n",
        "    # assertions.append(all_assertions.loc[all_assertions.chunks == n.result],'assertion'].values[0])\n",
        "    if (len(matching_assertions) > 0):\n",
        "      matching_assertions = matching_assertions.values[0]\n",
        "    assertions.append(matching_assertions)\n",
        "\n",
        "    # assertions.append(matching_assertions)\n",
        "      # relations.append(all_relations.loc[all_relations['chunk1'] == n.result] or all_relations.loc[df['chunk2'] == n.result])\n",
        "    \n",
        "    # relations.append(all_relations.loc[all_relations['chunk1'] == n.result] or all_relations.loc[df['chunk2'] == n.result])\n",
        "      \n",
        "    df = pd.DataFrame({'sentence':sentences, 'begin': begins, 'end': ends, 'chunks': chunks, 'entity': entities, 'confidence': confidences, 'resolution': resolutions, 'assertion': assertions \n",
        "                      #  , 'relations': relations\n",
        "                       })\n",
        "\n",
        "    print(\"\\n \\n\", \"*\"*20, model_name, \"Model Results\", \"*\"*20)\n",
        "    \n",
        "    display(df)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE7JA6DABDa4"
      },
      "source": [
        "text2 = \"\"\"\n",
        " 67 year old with metastatic breast cancer, COPD (on chronic prednisone and home O2), \n",
        "            paroxysmal afib who presents with worsening SOB and some confusion. \n",
        "            She has had malignant left pleural effusion that was last drained DATE[Feb 10].\n",
        "            She is taking tamoxifen for her breast cancer. She was last admitted on 02/02/2018 and discharged with home hospice/palliative care. \n",
        "            In terms of her cardiac issues, she was reportedly diagnosed with afib in 2011. \n",
        "            She had an echo at that time showing normal LV function. Most recently, she had an echo DATE[Nov 2012] showing EF 35-40%. \n",
        "            It does not appear that she underwent any ischemia evaluation. \n",
        "\"\"\""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv1a4B5XHmHA"
      },
      "source": [
        "clinical_full_result = clinical_profiling_pipeline.fullAnnotate(text2)[0]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWB3KLSY7TgY"
      },
      "source": [
        "def get_relations_extraction(text, pipeline):\n",
        "  \n",
        "  print('Will now try to extract relations for:',text)\n",
        "  \n",
        "  empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "  model = pipeline.fit(empty_data)\n",
        "\n",
        "  light_model = LightPipeline(model)\n",
        "  annotations = light_model.fullAnnotate(text)\n",
        "\n",
        "  print('annotations are:', annotations)\n",
        "\n",
        "  rel_df = get_relations_df (annotations)\n",
        "  print('rel_df is:',rel_df)\n",
        "\n",
        "  return rel_df"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQKzecVq2PrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcb355d-a84f-4094-9749-1f4992fffb4d"
      },
      "source": [
        "clinical_full_result['ner_drugs_greedy_chunks']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Annotation(chunk, 62, 71, prednisone, {'entity': 'DRUG', 'sentence': '0', 'chunk': '0', 'confidence': '0.7363'}),\n",
              " Annotation(chunk, 287, 295, tamoxifen, {'entity': 'DRUG', 'sentence': '2', 'chunk': '1', 'confidence': '0.9987'})]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q_0ouWlPkj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1288382b-3f16-4ef8-ad99-cda92160ba63"
      },
      "source": [
        "print(\"Clinical Text:\\n\", text2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clinical Text:\n",
            " \n",
            " 67 year old with metastatic breast cancer, COPD (on chronic prednisone and home O2), \n",
            "            paroxysmal afib who presents with worsening SOB and some confusion. \n",
            "            She has had malignant left pleural effusion that was last drained DATE[Feb 10].\n",
            "            She is taking tamoxifen for her breast cancer. She was last admitted on 02/02/2018 and discharged with home hospice/palliative care. \n",
            "            In terms of her cardiac issues, she was reportedly diagnosed with afib in 2011. \n",
            "            She had an echo at that time showing normal LV function. Most recently, she had an echo DATE[Nov 2012] showing EF 35-40%. \n",
            "            It does not appear that she underwent any ischemia evaluation. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdrsnOtcwAU3"
      },
      "source": [
        "# ner_posology_pipeline = get_ner_posology_pipeline()\n",
        "# ner_posology_chunks_result = clinical_full_result['ner_posology_chunks']\n",
        "\n",
        "# print(ner_posology_chunks_result)\n",
        "# get_drugs_chunk_result(text, ner_posology_chunks_result, 'ner_posology_chunks', ner_posology_pipeline)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0sTfPCQHsfm"
      },
      "source": [
        "# ner_drugs_chunks_result = clinical_full_result['ner_drugs_greedy_chunks']\n",
        "# pipeline = get_ner_drugs_pipeline()\n",
        "# print(ner_drugs_chunks_result)\n",
        "# get_drugs_chunk_result(text, ner_drugs_chunks_result, 'ner_drugs_greedy_chunks', pipeline)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWX_KFJbjcCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "540663c7-1c49-407a-f26d-9df8c756b4ac"
      },
      "source": [
        "ner_diseases_chunks_result = clinical_full_result['ner_diseases_chunks']\n",
        "pipeline = get_ner_diseases_pipeline()\n",
        "print(ner_diseases_chunks_result)\n",
        "get_diseases_chunk_result(text, ner_diseases_chunks_result, 'ner_diseases_chunks', pipeline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[ \\ ]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sAWCaLdyJh_"
      },
      "source": [
        "text3_family_history = \"Mother with a history of metastatic breast cancer.\"\n",
        "ner_diseases_chunks_result = clinical_full_result['ner_diseases_chunks']\n",
        "pipeline = get_ner_diseases_pipeline()\n",
        "print(ner_diseases_chunks_result)\n",
        "get_diseases_chunk_result(text3_family_history, ner_diseases_chunks_result, 'ner_diseases_chunks', pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roat4B6EPxJg"
      },
      "source": [
        "stage_t1 = \"\"\"HPI:\n",
        "From 3/11/2010 to April 2010 the patient received adjuvant chemotherapy (Taxol and carboplatin x 3 cycles). \"\"\"\n",
        "stage_t2 = \"\"\"\n",
        "HPI:\n",
        "He was diagnosed with stage IV non-small cell lung cancer in Oct 1991 and has received cyberknife for brain lesions, carboplatin, pemetrexed, and PF-[**Telephone/Fax (3) 7932**] as part of a clinical trial.  He discontinued this trial [**Doctor Last Name 23**] on 2/92 because of clinical (worsening dyspena) and radiolographic evidence of cancer progression.   He then started a new [**Doctor Last Name 23**], Alimta, on 10-11-1993.\n",
        "\"\"\"\n",
        "stage_t3 = \"\"\"\n",
        "Sample Type / Medical Specialty:\n",
        "Hematology - Oncology\n",
        "Sample Name:\n",
        "Consult - Breast Cancer\n",
        "Description:\n",
        "Patient presents with complaint of lump in the upper outer quadrant of the right breast\n",
        "(Medical Transcription Sample Report)\n",
        "CHIEF COMPLAINT / REASON FOR THE VISIT:\n",
        "Patient has been diagnosed to have breast cancer.\n",
        "BREAST CANCER HISTORY:\n",
        "Patient presented with the following complaints: Lump in the upper outer quadrant of the right breast that has been present for the last 4 weeks. The lump is painless and the skin over the lump is normal. Patient denies any redness, warmth, edema and nipple discharge. Patient had a mammogram recently and was told to have a mass measuring 2 cm in the UOQ and of the left breast. Patient had an excisional biopsy of the mass and subsequently axillary nodal sampling.\n",
        "PATHOLOGY:\n",
        "Infiltrating ductal carcinoma, Estrogen receptor 56, Progesterone receptor 23, S-phase fraction 2., Her 2 neu 0 and all nodes negative.  \n",
        "STAGE:\n",
        "Stage I.\n",
        "TNM STAGE:\n",
        "T1, N0 and M0.\n",
        "SURGERY:\n",
        "S/P lumpectomy left breast and Left axillary node sampling. Patient is here for further recommendation.\n",
        "PAST MEDICAL HISTORY:\n",
        "Osteoarthritis for 5 years. ASHD for 10 years. Kidney stones recurrent for 10 years.\n",
        "SCREENING TEST HISTORY:\n",
        "Last rectal exam was done on 10/99. Last mammogram was done on 12/99. Last gynecological exam was done on 10/99. Last PAP smear was done on 10/99. Last chest x-ray was done on 10/99. Last F.O.B. was done on 10/99-X3. Last sigmoidoscopy was done on 1998. Last colonoscopy was done on 1996.\n",
        "IMMUNIZATION HISTORY:\n",
        "Last flu vaccine was given on 1999. Last pneumonia vaccine was given on 1996.\n",
        "FAMILY MEDICAL HISTORY:\n",
        "Father age 85, history of cerebrovascular accident (stroke) and hypertension. Mother history of CHF and emphysema that died at the age of 78. No brothers and sisters. 1 son healthy at age 54.\n",
        "PAST SURGICAL HISTORY:\n",
        "Appendectomy. Biopsy of the left breast 1996 - benign. Cholecystectomy.\n",
        "PERSONAL AND SOCIAL HISTORY:\n",
        "Marital status: Married. Smoking history: Smoked 1 PPD, quit 12 years ago and after smoking for 30 years. Alcohol history: Drinks socially. Denies any history of drug abuse.\n",
        "ALLERGIES:\n",
        "There are no known drug allergies.\n",
        "CURRENT MEDICATIONS:\n",
        "Aspirin 1 tab x 1 / day. Calan SR 120 mg. x 1 / day.\n",
        "REVIEW OF SYSTEMS:\n",
        "General: Patient feels fairly well. Patient denies history of fever, chills, night sweats and weight loss.\n",
        "Head and Eyes: Patient denies any problems relating to the head and eyes.\n",
        "Ears Nose and Throat: Patient has no problems related to the ears, nose or throat.\n",
        "Respiratory: Patient denies any respiratory complaints, such as cough, shortness of breath, chest pain, wheezing, hemoptysis, etc.\n",
        "Cardiovascular: Chest pain in the retrosternal area, Occasional anginal pain and patient describes it as a sensation of tightness. It radiates to the left shoulder. Patient denies any palpitation, syncope, paroxysmal nocturnal dyspnea and orthopnea.\n",
        "Gastrointestinal: Patient denies any nausea, vomiting, abdominal pain, dysphagia or any altered bowel movements.\n",
        "Genitourinary: Denies any genito-urinary complaints.\n",
        "Musculoskeletal: The patient denies any musculoskeletal complaints.\n",
        "Neurological: Patient denies any focal motor, sensory or other neurological symptoms.\n",
        "PHYSICAL EXAMINATION:\n",
        "General: Patient appears well developed, well nourished and healthy. Personality: pleasant and cooperative. Mental status: Alert and oriented. Stature: slender. ECOG performance score 0.\n",
        "HEENT: Examination of head, eyes, ears, nose and throat is unremarkable.\n",
        "Hematologic / Lymphatic: There is no palpable adenopathy in the inguinal, axillary, or cervical areas.\n",
        "Cardiovascular: Heart: Regular rhythm, normal rate without any murmurs or gallops.\n",
        "Breast: RIGHT BREAST: Within normal limits. LEFT BREAST: Consistency: slight induration noted due to recent surgery.\n",
        "Respiratory: Chest symmetrical, normal, breath sounds equal, bilateral symmetrical, no rales or rhonchi and no\n",
        "dullness to percussion.\n",
        "Abdomen / Gastrointestinal: Abdomen is soft, non-tender, and without palpable masses. No hepatosplenomegaly is appreciable.\n",
        "Extremities: Peripheral pulses are normal. There is no edema, cyanosis, clubbing or significant varicosities. No skin lesions identified.\n",
        "Musculoskelatal: No evidence of joint swelling, bone tenderness or muscle tenderness is appreciable.\n",
        "Neurological: Brief neurological examination reveals motor power grossly normal in all groups and no gross sensory or other abnormality appreciable.\n",
        "RADIOLOGY:\n",
        "Mammogram: A mass measuring 2X2 cm. in the upper outer quadrant of the left breast. Lab:\n",
        "LAB DATA:\n",
        "CMP (comprehensive metabolic panel): WNL. Liver function tests are WNL. CBC with diff shows WBC 3.2 / cmm. Hemoglobin 12.0 grams / dl, Platelets 250000 / cmm and it is dated 1/4/2000.\n",
        "IMPRESSION / DIAGNOSIS\n",
        ": Carcinoma of the left breast (174.9 - female), Upper outer quadrant (174.4)\n",
        "PATHOLOGY:\n",
        "Infiltrating ductal carcinoma. S/P lumpectomy and axillary node dissection. (Details as per HPI).\n",
        "DISCUSSION:\n",
        "Discussed in detail the diagnosis, prognosis and treatment alternatives. Options of treatment discussed. Side effects of Tamoxifen discussed in detail.\n",
        "RECOMMENDATIONS:\n",
        "Hormonal therapy with Tamoxifen and Radiation therapy to the breast is recommended.\n",
        "TESTS ORDERED:\n",
        "The following labs are to be drawn about a week or so prior to next appointment:\n",
        "HEMATOLOGY: CBC.\n",
        "CHEMISTRY: comprehensive metabolic panel (CMP) and liver function panel (LFT).\n",
        "MEDICATIONS PRESCRIBED:\n",
        "Nolvadex 20 mg. 1 time a day.\n",
        "FOLLOW-UP INSTRUCTIONS:\n",
        "Return to see William Smith.M.D. for follow up in 3 month (s). Make appointment to Radiation therapy.\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjh9Fzixkv_X"
      },
      "source": [
        "ner_diseases_chunks_result = clinical_full_result['ner_diseases_chunks']\n",
        "pipeline = get_ner_diseases_pipeline()\n",
        "print(ner_diseases_chunks_result)\n",
        "get_diseases_chunk_result(stage_t1, ner_diseases_chunks_result, 'ner_diseases_chunks', pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA_mUE_hwY7q"
      },
      "source": [
        "# ner_posology_greedy_chunks_result = clinical_full_result['ner_posology_greedy_chunks']\n",
        "# print(ner_posology_greedy_chunks_result)\n",
        "# get_chunk_result(text, ner_posology_greedy_chunks_result, 'ner_posology_greedy_chunks')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phFSKVmzf6o-"
      },
      "source": [
        "**Now we will show all NER labels of tokens in the same dataframe.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwrBq_bnw6KE"
      },
      "source": [
        "**cut** **here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsbQU63mfw-m"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_token_results(light_result):\n",
        "\n",
        "  tokens = [j.result for j in light_result[\"token\"]]\n",
        "  sentences = [j.metadata[\"sentence\"] for j in light_result[\"token\"]]\n",
        "  begins = [j.begin for j in light_result[\"token\"]]\n",
        "  ends = [j.begin for j in light_result[\"token\"]]\n",
        "  model_list = [ a for a in light_result.keys() if (a not in [\"sentence\", \"token\"] and \"_chunks\" not in a)]\n",
        "\n",
        "  df = pd.DataFrame({'sentence':sentences, 'begin': begins, 'end': ends, 'token':tokens})\n",
        "\n",
        "  for model_name in model_list:\n",
        "    \n",
        "    temp_df = pd.DataFrame(light_result[model_name])\n",
        "    temp_df[\"jsl_label\"] = temp_df.iloc[:,0].apply(lambda x : x.result)\n",
        "    temp_df = temp_df[[\"jsl_label\"]]\n",
        "\n",
        "    # temp_df = get_ner_result(model_name)\n",
        "    temp_df.columns = [model_name]\n",
        "    df = pd.concat([df, temp_df], axis=1)\n",
        "    \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b5qFhWugsMZ"
      },
      "source": [
        "# get_token_results(clinical_full_result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}